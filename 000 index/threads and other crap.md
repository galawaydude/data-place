Of course. I will meticulously convert your handwritten notes into structured Markdown, provide in-depth explanations for every topic, and enrich them with additional important details and concepts.

Here is the comprehensive breakdown of your notes on Threads and System Calls.

***

### Part 1: Your Notes Transcribed to Markdown

```markdown
# 6. Threads & System Calls

## I. System Calls

### A. Process Control System Calls
- End, abort
- load, execute
- create process, terminate process
- get process attributes, set process attributes
- wait for time
- wait event, signal event
- allocate and free memory

### B. File Manipulation System Calls
- create file, delete file
- open, close
- read, write, reposition
- get file attributes, set file attributes

### C. Device Manipulation System Calls
- request device, release device
- read, write, reposition
- get device attributes, set device attributes
- logically attach or detach devices

### D. Information Maintenance System Calls
- get time or date, set time or date
- get system data, set system data
- get process, file or device data
- set process, file or device data

### E. Communications Related System Calls
- create, delete communication connection
- send, receive messages
- transfer status information
- attach or detach remote devices

## II. Fork System Call (Fork / execve)
- Parent -> Child
- C Code Snippet:
  int i = fork();
  if (i == 0) {
    // child process
  }
  if (i != 0) {
    // parent process
  }
- Return value: 0 -> child process, pid of child -> parent process
- Memory Diagram: `fork()` creates a nearly identical copy of the parent's memory space for the child.

## III. Process vs. Threads

### Process (Fork)
- CPU-wise expensive -> Context switch required
- Memory-wise expensive -> Unnecessarily wasted (copied)
- **Comparison Table:**
  - **System Calls:** are involved
  - **Context Switching:** required
  - **Memory:** Different copies of code & data

### Threads (User-level)
- Inexpensive
- **Comparison Table:**
  - **System Calls:** No system call
  - **Context Switching:** Register set switch only
  - **Memory:** Same copies of code & data

### Thread States
- New, Ready, Run, Block, Terminated

## IV. Problems with User-Level Threads
1.  **Blocking System Calls:** A blocking system call from one thread will block the entire process (all threads).
2.  **Unfair Scheduling:** The kernel schedules the process, not the individual threads. If a process with 100 threads gets the same time slice as a process with 1 thread, each of the 100 threads gets very little CPU time.

## V. Kernel-Level Threads
- Kernel is involved in thread creation and it knows about all threads.
- Solves both problems of user-level threads.
- **Disadvantages:**
  1.  Expensive as compared to user-level threads.
  2.  Context switch required.
- **Expense Hierarchy:** Process > Kernel-Level Thread > User-Level Thread

## VI. Hybrid Threads (Solaris 2)
- A many-to-many model mapping multiple user-level threads to a smaller or equal number of "light-weight processes" (LWPs), which are then mapped to kernel-level threads.
```

***

### Part 2: In-Depth Explanations and Additional Concepts

Here is a detailed, expanded explanation of all the topics from your notes.

# Topic 1: System Calls - The Bridge to the Kernel

A **system call** is the fundamental way a program in "user mode" (like your web browser or a text editor) requests a service from the operating system's "kernel." The kernel is the core of the OS that has direct control over the system's hardware and resources. Programs can't just access the hard drive or network card directly; that would be chaotic and insecure. Instead, they must ask the kernel to do it for them via a system call.

**Analogy:** Think of the kernel as the manager of a large library (the computer's resources). You (a user program) cannot go into the restricted "stacks" (hardware) yourself. You must go to the front desk and fill out a request slip (make a system call). The librarian (the kernel) then fetches the book (data from a file) for you.

Your notes correctly categorize system calls based on their function. Let's explore each category.

### A. Process Control System Calls

These calls are for managing the lifecycle of processes. A **process** is essentially a program in execution.

*   **Create Process (`fork()`, `clone()`):** This creates a new process. In UNIX-like systems, `fork()` is famous for creating a near-exact duplicate of the calling process (the parent), which is called the child process.
*   **Terminate Process (`exit()`, `abort()`):** `exit()` allows a process to terminate itself gracefully. `abort()` causes an abnormal termination, often for unrecoverable errors.
*   **Load, Execute (`execve()`):** After a `fork()`, the child process often uses an `exec`-family call to replace its own memory space with a new program. This is how your shell runs commands: it `forks` itself, and the child process then `execs` the command you typed (e.g., `ls`).
*   **Get/Set Process Attributes (`getpid()`, `nice()`):** Processes have attributes like a Process ID (PID), scheduling priority, etc. These calls allow a process to query or modify these attributes. `getpid()` returns the process's own ID. `nice()` can be used to lower a process's scheduling priority.
*   **Wait (`wait()`, `sleep()`):** A process may need to pause. `wait()` is used by a parent process to wait for a child process to terminate. `sleep()` pauses the process for a specific amount of time.
*   **Event Management (`signal()`, `kill()`):** Processes can send signals to each other to notify them of events. `kill()` is used to send a signal (like `SIGTERM` to request termination) to another process.
*   **Allocate/Free Memory (`brk()`, `mmap()`):** While `malloc()` is a C library function, under the hood it uses system calls like `brk()` or `mmap()` to request memory from the kernel for the process's heap.

### B. & C. File and Device Manipulation

Functionally, these are very similar. In UNIX-like systems, almost everything, including hardware devices (like your keyboard or a USB drive), is represented as a file in the filesystem.

*   **Create/Delete (`creat()`, `unlink()`):** Create a new file or delete an existing one.
*   **Open/Close (`open()`, `close()`):** Before a process can use a file, it must `open()` it to get a **file descriptor**â€”a small integer that acts as a handle to that file. When finished, it must `close()` the file to release the resources.
*   **Read/Write (`read()`, `write()`):** The core I/O operations. A process uses these to read data from a file descriptor or write data to it.
*   **Reposition (`lseek()`):** Moves the read/write "cursor" within a file to a specific position.
*   **Get/Set Attributes (`stat()`, `chmod()`):** Retrieve metadata about a file (size, creation date, permissions) or change its attributes (e.g., change permissions with `chmod`).

### D. & E. Information and Communication

*   **Information Maintenance (`gettimeofday()`, `uname()`):** These calls allow a process to query system-wide information, like the current time or the OS version (`uname`).
*   **Communication (`socket()`, `bind()`, `send()`, `recv()`):** These calls are used for inter-process communication (IPC), especially over a network. You create a `socket`, `bind` it to an address, and then `send` or `receive` messages.

---

# Topic 2: The `fork()` System Call in Detail

The `fork()` system call is a cornerstone of process management in UNIX/Linux. Your notes capture its essence perfectly.

*   **Mechanism:** When a process (the parent) calls `fork()`, the kernel creates a new process (the child). The child process is an almost identical copy of the parent. It gets its own memory space, but the *contents* of that memory (code, data, stack) are copied from the parent.
*   **Return Value:** This is the clever part. `fork()` returns a value in *both* processes.
    *   In the **child process**, `fork()` returns `0`.
    *   In the **parent process**, `fork()` returns the **Process ID (PID)** of the newly created child. The PID is a unique positive integer.
    *   If `fork()` fails, it returns `-1` in the parent.

This is why the code snippet in your notes works:

```c
#include <stdio.h>
#include <unistd.h> // For fork()
#include <sys/wait.h> // For wait()

int main() {
    pid_t i = fork(); // pid_t is a signed integer type for process IDs

    if (i < 0) {
        // Fork failed
        fprintf(stderr, "Fork failed!\n");
        return 1;
    } else if (i == 0) {
        // This block is executed by the CHILD process
        printf("Hello from the child process! My PID is %d.\n", getpid());
    } else {
        // This block is executed by the PARENT process
        // 'i' holds the PID of the child
        printf("Hello from the parent process! I created a child with PID %d.\n", i);
        wait(NULL); // Parent waits for the child to finish
        printf("Child process has finished.\n");
    }
    return 0;
}
```

#### **Additional Point: Copy-on-Write (CoW)**

Your note "Memory wise expensive - unnecessarily wasted (copied)" is historically correct. A naive `fork()` would copy the entire memory space, which is very slow. Modern operating systems use a crucial optimization called **Copy-on-Write (CoW)**.

*   With CoW, after a `fork()`, the parent and child initially **share** the same physical memory pages.
*   A copy is only made if one of the processes tries to **write** to a shared page. The kernel intercepts the write, creates a private copy of that page for the writing process, and then allows the write to proceed.
*   This makes `fork()` extremely fast, especially when the child immediately calls `execve()`, as most of the parent's memory pages never need to be copied.

---

# Topic 3: Process vs. Threads - The Core Comparison

This is a central concept in concurrent programming.

*   **Process:** A process is an instance of a program running. It has its own private virtual address space, which contains its code, data, heap, and stack. It also has its own set of resources like file descriptors. Processes are isolated from each other by the OS.
    *   **Analogy:** A process is like a complete house. It has its own foundation (memory space), plumbing (resources), and address.
*   **Thread:** A thread is the smallest unit of execution within a process. A process can have multiple threads. All threads within a single process **share** the same memory space (code, data, heap) and resources (file descriptors). However, each thread has its own private **stack**, **registers**, and **program counter**.
    *   **Analogy:** Threads are like different people (or rooms) within the same house. They all share the same address, kitchen, and bathroom (memory and resources), but each person has their own private bedroom (stack) and their own thoughts (registers/program counter).

| Feature               | Process (`fork()`)                                      | Thread (e.g., `pthread_create()`)                         |
| --------------------- | ------------------------------------------------------- | --------------------------------------------------------- |
| **Memory & Data**     | **Separate.** Each process has its own copy of code, data, heap. | **Shared.** Threads share the code, data, and heap of the parent process. |
| **Private State**     | Entire address space is private.                        | Each thread has its own stack, registers, program counter. |
| **Creation**          | **Expensive.** Involves a system call (`fork()`). Requires significant kernel work (even with CoW). | **Cheap.** Often managed by a library. Creating a new thread is much faster. |
| **Context Switching** | **Expensive.** The OS must save the entire state of the process, flush caches, and update the Memory Management Unit (MMU). | **Cheap.** Since the address space is shared, the OS only needs to swap the registers and stack pointer. The MMU context remains the same. |
| **Communication**     | **Difficult.** Requires Inter-Process Communication (IPC) mechanisms like pipes, sockets, or shared memory, all managed by the kernel. | **Easy.** Threads can communicate directly by reading and writing to the shared data and heap. (This requires synchronization mechanisms like mutexes to prevent race conditions). |

---

# Topic 4 & 5: User-Level vs. Kernel-Level Threads

This distinction is about *who manages the threads*: a user-space library or the OS kernel itself.

### User-Level Threads (ULTs)

The kernel is completely unaware that threads exist. The entire process is seen by the kernel as a single entity. A user-space library (like an old `pthreads` implementation) manages all the thread creation, scheduling, and switching.

*   **Advantages:**
    *   **Extremely Fast:** No system calls are needed to create threads or switch between them. It's as fast as a function call.
*   **Disadvantages (as noted in your diagram):**
    1.  **Blocking System Calls:** If one user-level thread makes a blocking call (e.g., `read()` from the network), the kernel sees the *entire process* as blocked. It puts the whole process to sleep, and **no other threads in that process can run**, even if they are ready. This is a massive problem.
    2.  **No True Parallelism:** Because the kernel only sees one process, it will only ever schedule it on a single CPU core. You cannot achieve true parallelism on a multi-core machine with pure user-level threads.
    3.  **Unfair Scheduling:** The kernel gives a time slice to the process. It's up to the user-level scheduler to divide that time among its threads. This can be inefficient and unfair compared to other processes, as your notes correctly illustrate.

### Kernel-Level Threads (KLTs)

The kernel is aware of and manages every thread. Each thread is a schedulable entity for the OS. This is the dominant model used in all modern operating systems (Windows, Linux, macOS).

*   **Advantages:**
    *   **Solves the Blocking Problem:** If one kernel-level thread blocks on a system call, the kernel can simply schedule another ready thread from the same process to run.
    *   **True Parallelism:** The kernel can schedule multiple threads from the same process to run simultaneously on different CPU cores.
*   **Disadvantages:**
    *   **Higher Overhead:** Creating, terminating, and switching between kernel-level threads requires a system call and a context switch to kernel mode. While much cheaper than a full process switch, it is still more expensive than a simple function call for ULTs.

**Your Expense Hierarchy is spot on:**
**Process Creation (most expensive) > Kernel-Level Thread Creation > User-Level Thread Creation (least expensive)**

---

# Topic 6: Hybrid Threads (The Best of Both Worlds)

The hybrid model, also known as the "many-to-many" model, was an attempt to combine the benefits of both ULTs and KLTs. Your diagram of **Solaris 2** is the classic example.

*   **User-Level Threads:** The programmer creates as many cheap, fast user-level threads as they need.
*   **Light-Weight Processes (LWPs):** The OS provides a pool of LWPs. Each LWP is a kernel-schedulable entity, essentially a kernel-level thread.
*   **The Mapping:** The user-space thread library is responsible for mapping (multiplexing) the many user-level threads onto the smaller pool of LWPs.

**How it works:**
*   The application creates, say, 100 user-level threads.
*   The system might have 8 LWPs available for this process (perhaps because there are 8 CPU cores).
*   The thread library schedules the 100 threads to run on these 8 LWPs.
*   If a thread on LWP-1 makes a blocking system call, the kernel blocks LWP-1. The thread library can then schedule another ready user-level thread onto a different available LWP (e.g., LWP-2), so the application as a whole does not stop.

This model provides the flexibility of ULTs while getting the non-blocking benefits and parallelism of KLTs. However, it adds significant complexity to the thread library and scheduler. Due to this complexity and the fact that KLT performance has improved so much, most modern systems (like Linux with its NPTL implementation) have moved to a simpler **1:1 model**, where every user thread is directly backed by one kernel thread.